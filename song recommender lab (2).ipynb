{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ce7715",
   "metadata": {},
   "source": [
    "# scrap the website "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467ee34e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4cfb8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this lab, the chosen website is streamsquid.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7bbd8e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the first part of the task, we only import the necessary libraries for Py web scraping \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a90539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request and retrieve content \n",
    "url = 'https://streamsquid.com/#/browse/newrel'\n",
    "response = requests.get(url)\n",
    "content = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b5b7a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse content \n",
    "soup = BeautifulSoup(content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f135cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the container \n",
    "container = soup.find('div', class_=\"s-scroller\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6f75d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"s-scroller\">\n",
       "<div class=\"results s-scroller-item\"></div>\n",
       "</div>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f4ce017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the name for the csv file where I will store the output will be \"playlist.csv\"\n",
    "playlist = \"playlist.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8e5868",
   "metadata": {},
   "source": [
    "# important checkpoint: retrieve the output in csv format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98ea6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the search box, we can perform searches by song title, artist and album, this is the information that we extract \n",
    "headers = [\"Song Title\", \"Artist\", \"Album\"]\n",
    "with open(playlist, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(headers)\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e5571",
   "metadata": {},
   "source": [
    "# start working with the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fea32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a66f7ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Album</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Song Title, Artist, Album]\n",
       "Index: []"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist = pd.read_csv('playlist.csv')\n",
    "playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e9d391cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Song Title Artist Album\n",
      "count           0      0     0\n",
      "unique          0      0     0\n",
      "top           NaN    NaN   NaN\n",
      "freq          NaN    NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "# get summary statistics from the dataset\n",
    "print(playlist.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72795dd1",
   "metadata": {},
   "source": [
    "# summary of csv dataset operations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f8ac35",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA): Perform EDA to understand the structure, characteristics, and relationships within the dataset. Some common tasks include examining the dimensions of the dataset, checking for missing values, exploring data distributions, and visualizing patterns and relationships using plots or summary statistics.\n",
    "\n",
    "Data Preprocessing: Prepare the dataset for machine learning algorithms by handling missing data, encoding categorical variables, normalizing or scaling numerical features, and handling outliers. Pandas provides functions to handle missing values (fillna()), encode categorical variables (get_dummies()), and perform various transformations.\n",
    "\n",
    "Feature Selection/Engineering: Select or engineer relevant features that can contribute to the machine learning task. This may involve dropping irrelevant or highly correlated features, creating new features through mathematical operations or domain knowledge, or extracting information from text or images.\n",
    "\n",
    "Splitting the Dataset: Split the dataset into training and testing sets. The training set is used to train the machine learning model, while the testing set is used to evaluate its performance. Scikit-learn provides functions like train_test_split() to split the dataset into appropriate proportions.\n",
    "\n",
    "Model Training: Choose a suitable machine learning algorithm based on your task (classification, regression, clustering, etc.) and train the model using the training data. Scikit-learn provides various algorithms like decision trees, random forests, support vector machines (SVM), and neural networks, among others. Use the fit() function to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d121ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploratory data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe443f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe185ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f9569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e11a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a042c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e91cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4ab5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79b7946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9c7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0471d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545842e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a359bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary and highlights of key findings "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
